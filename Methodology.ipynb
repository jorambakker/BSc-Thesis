{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the data from CSV (adjust the path as needed)\n",
    "d = pd.read_csv(\"CG Uncertainty.csv\", parse_dates=['date'])\n",
    "# Filter years between 1996 and 2022\n",
    "d = d[(d['date'].dt.year >= 1996) & (d['date'].dt.year <= 2022)].copy()\n",
    "\n",
    "# Inspect the data\n",
    "d.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate For_error and For_revision based on Annualized Variance\n",
    "d['For_error'] = d['Annualized Variance'] - d['avg_impl_variance30']\n",
    "d['For_revision'] = d['avg_impl_variance30'] - d['Forecast,t-1 of X(t,t+h)']\n",
    "\n",
    "# Inspect the newly created columns\n",
    "d[['date', 'For_error', 'For_revision']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CG Model: Regress For_error on For_revision ===\")\n",
    "\n",
    "# Clean the data: drop rows with NaN or infinite values\n",
    "d_model1 = d[['For_revision', 'For_error']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "X1 = sm.add_constant(d_model1['For_revision'])\n",
    "y1 = d_model1['For_error']\n",
    "\n",
    "model1 = sm.OLS(y1, X1).fit()\n",
    "print(model1.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the column 'h=1' exists\n",
    "if 'h=1' in d.columns:\n",
    "    print(\"=== CG Model with Uncertainty Extension (Equation 6) ===\")\n",
    "    # Recalculate to be sure\n",
    "    d['For_error'] = d['Annualized Variance'] - d['avg_impl_variance30']\n",
    "    d['For_revision'] = d['avg_impl_variance30'] - d['Forecast,t-1 of X(t,t+h)']\n",
    "    \n",
    "    # Create an interaction term between For_revision and h=1\n",
    "    d['interaction'] = d['For_revision'] * d['h=1']\n",
    "    \n",
    "    # Clean data for regression\n",
    "    d_model2 = d[['For_revision', 'h=1', 'interaction', 'For_error']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    X2 = sm.add_constant(d_model2[['For_revision', 'h=1', 'interaction']])\n",
    "    y2 = d_model2['For_error']\n",
    "    \n",
    "    model2 = sm.OLS(y2, X2).fit()\n",
    "    print(model2.summary())\n",
    "else:\n",
    "    print(\"Column 'h=1' not found in the data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lag_h1' in d.columns:\n",
    "    print(\"=== CG Model Extension: For_error ~ For_revision + For_revision*lag_h1 ===\")\n",
    "    \n",
    "    # Create an interaction term using lag_h1\n",
    "    d['interaction2'] = d['For_revision'] * d['lag_h1']\n",
    "    \n",
    "    # Clean data for regression\n",
    "    d_model3 = d[['For_revision', 'lag_h1', 'interaction2', 'For_error']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    X3 = sm.add_constant(d_model3[['For_revision', 'lag_h1', 'interaction2']])\n",
    "    y3 = d_model3['For_error']\n",
    "    \n",
    "    model3 = sm.OLS(y3, X3).fit()\n",
    "    print(model3.summary())\n",
    "else:\n",
    "    print(\"Column 'lag_h1' not found in the data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'historical variance' in d.columns:\n",
    "    print(\"=== CG Model with Historical Variance ===\")\n",
    "    \n",
    "    d['For_error'] = d['historical variance'] - d['avg_impl_variance30']\n",
    "    d['For_revision'] = d['avg_impl_variance30'] - d['Forecast,t-1 of X(t,t+h)']\n",
    "    \n",
    "    d_model4 = d[['For_revision', 'For_error']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    X4 = sm.add_constant(d_model4['For_revision'])\n",
    "    y4 = d_model4['For_error']\n",
    "    \n",
    "    model4 = sm.OLS(y4, X4).fit()\n",
    "    print(model4.summary())\n",
    "else:\n",
    "    print(\"Column 'historical variance' not found in the data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'historical variance' in d.columns and 'h=1' in d.columns:\n",
    "    print(\"=== CG Model with Historical Variance + Uncertainty Extension ===\")\n",
    "    \n",
    "    # Use the previously recalculated For_error and For_revision\n",
    "    d['interaction_hist'] = d['For_revision'] * d['h=1']\n",
    "    \n",
    "    d_model5 = d[['For_revision', 'interaction_hist', 'For_error']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    X5 = sm.add_constant(d_model5[['For_revision', 'interaction_hist']])\n",
    "    y5 = d_model5['For_error']\n",
    "    \n",
    "    model5 = sm.OLS(y5, X5).fit()\n",
    "    print(model5.summary())\n",
    "else:\n",
    "    print(\"Required columns for model 5 not found in the data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Stein data\n",
    "df = pd.read_csv(\"Stein data thesis.csv\", parse_dates=['date'])\n",
    "df = df[(df['date'].dt.year >= 1996) & (df['date'].dt.year <= 2022)].copy()\n",
    "\n",
    "# AR(1) regression on avg_impl_variance30\n",
    "df['lag_var30'] = df['avg_impl_variance30'].shift(1)\n",
    "df_model = df[['avg_impl_variance30', 'lag_var30']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "print(\"=== STEIN AR(1) with Monthly Data (Equation 3) ===\")\n",
    "X = sm.add_constant(df_model['lag_var30'])\n",
    "y = df_model['avg_impl_variance30']\n",
    "model_ar1 = sm.OLS(y, X).fit()\n",
    "print(model_ar1.summary())\n",
    "\n",
    "# Equation 1: Spread analysis\n",
    "mean_variance = df['historical variance'].mean(skipna=True)\n",
    "df['spread_short'] = df['avg_impl_variance30'] - mean_variance\n",
    "df['spread_long'] = df['avg_impl_variance60'] - mean_variance\n",
    "df_model2 = df[['spread_short', 'spread_long']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "print(\"=== STEIN Equation 1: spread_long ~ spread_short ===\")\n",
    "X2 = sm.add_constant(df_model2['spread_short'])\n",
    "y2 = df_model2['spread_long']\n",
    "model_spread = sm.OLS(y2, X2).fit()\n",
    "print(model_spread.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stein daily analysis using lag variables and volatility\n",
    "df = pd.read_csv(\"Stein data thesis.csv\", parse_dates=['date'])\n",
    "df = df[(df['date'].dt.year >= 1996) & (df['date'].dt.year <= 2022)].copy()\n",
    "\n",
    "print(\"=== Stein Daily Analysis: 1-week lag ===\")\n",
    "df_1w = df[['avg_impl_variance30','var30_lag1w']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "X_1w = sm.add_constant(df_1w['var30_lag1w'])\n",
    "y_1w = df_1w['avg_impl_variance30']\n",
    "model_1w = sm.OLS(y_1w, X_1w).fit()\n",
    "print(model_1w.summary())\n",
    "\n",
    "# Similar cells can be written for 2-week, 3-week, and 4-week lags.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
